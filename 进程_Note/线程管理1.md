# 线程管理

## 启动线程

线程在 std::thread 对象创建（为线程指定任务）时启动。

例如：

```c++
void do_some_work();
std::thread my_thread(do_some_work);
```

为了让编译器识别到 std::thread 类，这个简单的例子也要包含 <thread> 头文件。如同大多数c++标准库一样，std::thread 可以用可调用类型构造，将带有函数调用符类型的实例传入 std::thread 类中，替换默认的构造函数。

```c++
class background_task {
    public:
    	void operator()() const {
            do_something();
            do_something_else();
        }
};

background_task f;
std::thread my_thread(f);
```

代码中，提供的函数对象复制到新线程的存储空间当中，函数对象的执行和调用都在线程的内存空间中进行。函数对象的副本应与原始函数对象保持一致，否则得到的结果会与我们的期望不同。

如果你传递了一个临时变量，而不是一个命名的变量；C++编译器会将其解析为函数声明，而不是类型对象的定义。

例如：

```c++
std::thread my_thread(background_task());
```

这里相相当于声明了一个名为 my_thread 的函数，这个函数带有一个参数（函数指针指向没有参数并返回 background_task对象的函数），返回一个 std::thread 对象的函数，而非启动了一个线程。

使用在前面命名函数对象的方式，或使用多组括号①，或使用新统一的初始化语法②，可以避免这个问题。

```c++
std::thread my_thread((background_task()));	//1
std::thread my_thread{background_task()};	//2
```

使用 lambda 表达式也能避免这个问题。lambda表达式是C++11的一个新特性，它允许使用一个可以捕获局部变量的局部函数(可以避免传递参数，参见2.2节)。想要具体的了解lambda表达式，可以阅读附录A的A.5节。之前的例子可以改写为lambda表达式的类型：

```c++
std::thread my_thread([]{
    do_something();
    do_something_else();
});
```

启动了线程，你需要明确是要等待线程结束，还是让其自主运行。如果 std::thread 对象销毁之前还没有做出决定，程序就会终止( std::thread 的析构函数会调用 std::terminate() )。因此，即便是有异常存在，也需要确保线程能够正确的加入(joined)或分离(detached)。会介绍对应的方法来处理这两种情况。需要注意的是，必须在 std::thread 对象销毁之前做出决定，否则你的程序将会终止( std::thread 的析构函数会调用 std::terminate() ，这时再去决定会触发相应异常)。

如果不等待线程，就必须保证线程结束之前，可访问的数据得有效性。这不是一个新问题——单线程代码中，对象销毁之后再去访问，也会产生未定义行为——不过，线程的生命周期增加了这个问题发生的几率。这种情况很可能发生在线程还没结束，函数已经退出的时候，这时线程函数还持有函数局部变量的指针或引用。下面的清单中就展示了这样的一种情况。

```c++
struct func {
    int& i;
    func(int& i_) : i(i_) {}
    void operator()() {
        for (unsigned j = 0; j < 1000000; ++j) {
            do_something(i);		//1 存在访问隐患：悬空引用
        }
    }
};

void oops() {
    int some_local_state = 0;
    func mu_func(some_local_state);
    std::thread my_thread(my_func);
    my_thread.detach();		// 2 不等待线程结束
}							// 3  新线程可能还在运行
```

这个例子中，已经决定不等待线程结束(使用了detach() ② )，所以当oops()函数执行完成时③，新线程中的函数可能还在运行。如果线程还在运行，它就会去调用do_something(i)函数①，这时就会访问已经销毁的变量。如同一个单线程程序——允许在函数完成后继续持有局部变量的指针或引用；当然，这从来就不是一个好主意——这种情况发生时，错误并不明显，会使多线程更容易出错。

## 等待线程完成

如果需要等待线程，相关的 std::thread 实例需要使用join()。将 my_thread.detach() 替换为 my_thread.join() ，就可以确保局部变量在线程完成后，才被销毁。在这种情况下，因为原始线程在其生命周期中并没有做什么事，使得用一个独立的线程去执行函数变得收益甚微，但在实际编程中，原始线程要么有自己的工作要做；要么会启动多个子线程来做一些有用的工作，并等待这些线程结束。

join()是简单粗暴的等待线程完成或不等待。当你需要对等待中的线程有更灵活的控制时，比如，看一下某个线程是否结束，或者只等待一段时间(超过时间就判定为超时)。想要做到这些，你需要使用其他机制来完成，比如条件变量和期待(futures)，相关的讨论将会在第4章继续。调用join()的行为，还清理了线程相关的存储部分，这样 std::thread 对象将不再与已经完成的线程有任何关联。这意味着，只能对一个线程使用一次join();一旦已经使用过join()， std::thread 对象就不能再次加入了，当对其使用joinable()时，将返回false。

## 特殊情况下的等待

如前所述，需要对一个还未销毁的 std::thread 对象使用join()或detach()。如果想要分离一个线程，可以在线程启动后，直接使用detach()进行分离。如果打算等待对应线程，则需要细心挑选调用join()的位置。当在线程运行之后产生异常，在join()调用之前抛出，就意味着这次调用会被跳过。

避免应用被抛出的异常所终止，就需要作出一个决定。通常，当倾向于在无异常的情况下使用join()时，需要在异常处理过程中调用join()，从而避免生命周期的问题。下面的程序清单是一个例子。

```c++
struct func;		// 以上已经定义
void f() {
    int some_local_state = 0;
    func my_func(some_local_state);
    std::thread t(my_func);
    try {
        do_something_in_current_thread();
    }
    catch(...) {
        t.join();	//1
        throw;
    }
    t.join();	//2
}
```

代码使用了 try/catch 块确保访问本地状态的线程退出后，函数才结束。当函数正常退出时，会执行到②处；当函数执行过程中抛出异常，程序会执行到①处。 try/catch 块能轻易的捕获轻量级错误，所以这种情况，并非放之四海而皆准。如需确保线程在函数之前结束——查看是否因为线程函数使用了局部变量的引用，以及其他原因——而后再确定一下程序可能会退出的途径，无论正常与否，可以提供一个简洁的机制，来做解决这个问题。

一种方式是使用“资源获取即初始化方式”(RAII，Resource Acquisition Is Initialization)，并且提供一个类，在析构函数中使用**join()**，如同下面清单中的代码。看它如何简化f()函数。

```c++
class thread_guard {
    std::thread& t;
    public:
    	explicit thread_guard(std::thread& t_) : t(t_) {}
    	~thread_guard() {
            if(t.joinable()) //1
            {
                t.join();	//2
            }
        }
    thread_guard(thread_guard const&) = delete;		//3
    thread_guard& operator=(thread_guard const&) = delete;
};

struct func; // 以上已经定义

void f() {
    int some_local_state = 0;
    func my_func(some_local_state);
    std::thread t(my_func);
    thread_guard g(t);
    do_something_in_current_thread();
}	// 4
```

当线程执行到④处时，局部对象就要被逆序销毁了。因此，thread_guard对象g是第一个被销毁的，这时线程在析构函数中被加入②到原始线程中。即使do_something_in_current_thread抛出一个异常，这个销毁依旧会发生。在thread_guard的析构函数的测试中，首先判断线程是否已加入①，如果没有会调用join()②进行加入。这很重要，因为join()只能对给定的对象调用一次，所以对给已加入的线程再次进行加入操作时，将会导致错误。

拷贝构造函数和拷贝赋值操作被标记为 =delete ③，是为了不让编译器自动生成它们。直接对一个对象进行拷贝或赋值是危险的，因为这可能会弄丢已经加入的线程。通过删除声明，任何尝试给thread_guard对象赋值的操作都会引发一个编译错误。

如果不想等待线程结束，可以分离_(_detaching)线程，从而避免异常安全(exception-safety)问题。不过，这就打破了线程与 std::thread 对象的联系，即使线程仍然在后台运行着，分离操作也能确保 std::terminate() 在 std::thread 对象销毁才被调用。

## 后台运行线程

使用detach()会让线程在后台运行，这就意味着主线程不能与之产生直接交互。也就是说，不会等待这个线程结束；如果线程分离，那么就不可能有 std::thread 对象能引用它，分离线程的确在后台运行，所以分离线程不能被加入。不过C++运行库保证，当线程退出时，相关资源的能够正确回收，后台线程的归属和控制C++运行库都会处理。

通常称分离线程为守护线程(daemon threads)，UNIX中守护线程是指，没有任何显式的用户接口，并在后台运行的线程。这种线程的特点就是长时间运行；线程的生命周期可能会从某一个应用起始到结束，可能会在后台监视文件系统，还有可能对缓存进行清理，亦或对数据结构进行优化。另一方面，分离线程的另一方面只能确定线程什么时候结束，发后即忘(fireand forget)的任务就使用到线程的这种方式。

调用 std::thread 成员函数detach()来分离一个线程。之后，相应的 std::thread 对象就与实际执行的线程无关了，并且这个线程也无法加入：

```c++
std::thread t(do_background_work);
t.detach();
assert(!t.joinable());
```

为了从 std::thread 对象中分离线程（前提是有可能进行分离线程），不能对没有执行的线程的 std::thread 对象使用 detach(), 也是 join() 的使用条件，并且要用同样的方式进行检查——当 std::thread 对象使用 t.joinable() 返回的是 true ，就可以使用 t.detach()。

例如：分离线程

```c++
void edit_document(std::string const& filename) {
    open_document_and_display_gui(filename);
    while(!done_editing()) {
        user_command cmd = get_uer_input();
        if(cmd.type == open_new_document) {
            std::string const new_name = get_filenme_from_user();
            std::thread t(edit_document, new_name);		// 1
            t.detach();		// 2
        }
        else {
            process_user_input(cmd);
        }
    }
}
```

如果选择打开一个新文档，需要启动一个新线程去打开新文档①，并分离线程②。与当前线程做出的操作一样，新线程只不过是打开另一个文件而已。所以，edit_document函数可以复用，通过传参的形式打开新的文件。

这个例子也展示了传参启动线程的方法：不仅可以向 std::thread 构造函数①传递函数名，还可以传递函数所需的参数(实参)。C++线程库的方式也不是很复杂。当然，也有其他方法完成这项功能，比如:使用一个带有数据成员的成员函数，代替一个需要传参的普通函数。

## 向线程函数传递参数

向 std::thread 构造函数中的可调用对象，或函数传递一个参数很简单。需要注意的事，默认参数需要拷贝到线程独立内存中，即使参数是引用的形式，也可以在新线程中进行访问。例如：

```c++
void f(int i, std::string const& s);
std::thread t(f, 3, "hello");
```

代码创建了一个调用 f(3, "hello") 的线程。注意，函数 f 需要一个 std::thread 对象作为第二个参数，但这里使用的事字符串的字面值，也就是 char const * 类型。之后，在线程的上下文中完成字面值向 std::string 对象的转化。需要注意的是，当指向动态变量的指针作为参数传递给线程的情况，代码如下：

```c++
void f(int i, std::string const& s);
void oops(int some_param) {
    char buffer[1024];	//1
    sprintf(buffer, "%i", some_param);
    std::thread t(f, 3, buffer);	//2
    t.detach();
}
```

这种情况下，buffer①是一个指针变量，指向本地变量，然后本地变量通过buffer传递到新线 程中②。并且，函数有很有可能会在字面值转化成 std::string 对象之前崩溃(oops)，从而导致一些未定义的行为。并且想要依赖==隐式==转换将字面值转换为函数期待的 std::string 对象， 但因 std::thread 的构造函数会复制提供的变量，就只复制了没有转换成期望类型的字符串字面值。

解决方案就是传递到 std::thread 构造函数之前就字面值转化为 std::string 对象：

```c++
void f(int i, std::string const& s);
void not_oops(int some_param) {
    char buffer[1024];
    sprintf(buffer, "%i", some_param);
    std::thread t(f, 3, std::string(buffer));	// 使用 std::string 避免垂直指针
    t.detach();
}
```

这可能遇到相反的情况：期望传递一个非常量引用（但这不会被编译），但整个对象被复制了。

比如：

```c++
void update_data_for_widget(widget_id w, widget_date& data); //1
void oops_again(widget_id w) {
    winget_data data;
    std::thread t(update_data_for_widget, w, data);	//2
    display_status();
    t.join();
    process_widget_date(data);
}
```

虽然update_data_for_widget①的第二个参数期待传入一个==引用==，但是 ==std::thread== 的构造函 数②并不知晓；构造函数无视函数期待的参数类型，并盲目的拷贝已提供的变量。不过，在代码会将参数以右值的方式进行拷贝传递，这是为了照顾到那些只能进行移动的类型，而后会以右值为参数调用update_data_for_widget。

因为函数期望的是一个非常量引用作为参数，而非一个右值作为参数，所以会在编译时出错。对于熟悉 std::bind 的开发者来说，问题的解决办法是显而易见的：可以使用 ==std::ref== 将参数转换成引用的形式，从而可将线程的调用改为以下形式： 

```c++
std::thread t(update_data_for_widget, w, std::ref(data));
```

在这之后，update_data_for_widget就会接收到一个==data变量的引用==，而非一个data变量==拷贝的引用==，这样代码就能顺利的通过编译。 

如果你熟悉 ==std::bind== ，就应该不会对以上述传参的形式感到奇怪，因为 std::thread 构造函 数和 std::bind 的操作都在标准库中定义好了，可以传递一个==成员函数指针==作为线程函数， 并提供一个合适的对象指针作为第一个参数：

```c++
class x {
    public:
    	void do_lengthy_work();
};
x my_x;
std::thread t(&x::do_lengthy_work, &my_x);	//1
```

这段代码中，新线程将 ==my_x.do_lengthy_work() 作为线程函数==；my_x的地址①作为指针对象提供给函数。也可以为成员函数提供参数： std::thread 构造函数的第三个参数就是成员函数的第一个参数，以此类推

```c++
class x {
    public:
    	void do_lengthy_work();
};
x my_x;
int num(0);
std::thread t(&x::do_lengthy_work, &my_x, num);	
```

提供的参数可以移动，但不能拷贝。"移动"是指：原始对象中的数据转移给另一对象，而转移的这些数据就不再在原始对象中保存了(译者：比较像在文本编辑的"剪切"操 作)。 std::unique_ptr 就是这样一种类型(译者：C++11中的智能指针)，这种类型为动态分配 的对象提供内存自动管理机制(译者：类似垃圾回收)。同一时间内，只允许一 个 std::unique_ptr 实现指向一个给定对象，并且当这个实现销毁时，指向的对象也将被删除。移动构造函数(move constructor)和移动赋值操作符(move assignment operator)允许一个对象在多个 std::unique_ptr 实现中传递。 

使用"移动"转移原对象后，就会留下一个空指针(NULL)。移动操作可以将对象转换成可接受的类型，例如:函数参数或函数返回的类型。当原对象是一个临时变量时，自动进行移动操作， 但当原对象是一个命名变量，那么转移的时候就需要使用 std::move() 进行显示移动。

下面的代码展示了 std::move 的用法，展示了 std::move 是如何转移一个动态对象到一个线程中去的： 

```c++
void process_big_object(std::unique_ptr<big_object>);
std::unique_ptr<big_object> p(new big_object);
p->prepare_data(42);
std::thread t(process_big_object, std::move(p));
```

std::thread 的构造函数中指定 std::move(p)，big_object 对象的所有权就被首先转移到新创建线程的内部存储中，之后传递给 process_big_object 函数。

c++标准线程库中和 std::unique_ptr 在所属权上有相似语义类型的类有好几种， std::thread 为其中之一。虽然， std::thread 实例不像 std::unique_ptr 那样能占有一个动态对象的所有权，但是它能占有其他资源：每个实例都负责管理一个执行线程。执行线程的所有权可以在多个 std::thread 实例中互相转移，这是依赖于 std::thread 实例的可移动且不可复制性。不可复制保证了在同一时间点，一个 std::thread 实例只能关联一个执行线程；可移动性使得开发者可以自己决定，哪个实例拥有实际执行线程的所有权。

## 转移线程所有权

假设要写一个在后台启动线程的函数，并想通过新线程返回的所有权去调用这个函数，而不是等待线程结束再去调用；或完全与之相反的想法：创建一个线程，并在函数中转移所有 权，都必须要等待线程结束。所以，新线程的所有权都需要转移。 

这就是将移动操作引入 std::thread 的原因，C++标准库中有很多资源占有(resource-owning)类型，比如 std::ifstream ， std::unique_ptr 还有 std::thread 都是可移动，但不可拷贝。这就说明执行线程的所有权可以在 std::thread 实例中移动，下面将展示一个例子。例子中，创建了两个执行线程，并且在 std::thread 实例之间(t1,t2和t3)转移所有权： 

```c++
void some_function();
void some_other_function();
std::thread t1(some_function);	//1
std::thread t2 = std::move(t1);		//2
t1 = std::thread(some_other_function);	//3
std::thread t3;		//4
t3 = std::move(t2);		//5
t1 = std::move(t3);		// 6 赋值操作将使程序崩溃
```

首先，新线程开始与 t1 相关联①。当显式使用 std::move() 创建 t2 后②，t1 的==所有权==就转移给了 t2。之后，t1和执行线程已经没有关联了，执行some_function的函数线程与 t2 关联。 

然后，一个临时 std::thread 对象相关的线程启动了 ③。为什么不显式调用 std::move() 转移所有权呢？因为，所有者是一个临时对象——移动操作将会隐式的调用。 

t3 使用默认构造方式创建④，与任何执行线程都没有关联。调用 std::move() 将与 t2 关联线程的所有权转移到 t3中⑤。因为t2是一个命名对象，需要显式的调用 std::move() 。移动操作 #5 完成后，t1与执行some_other_function的线程相关联，t2与任何线程都无关联，t3与执行 some_function的线程相关联。 

最后一个移动操作，将some_function线程的所有权转移⑥给t1。不过，t1 已经有了一个关联的线程(执行some_other_function的线程)，所以这里系统直接调用 std::terminate() 终止程序继续运行。这样做（不抛出异常， std::terminate() 是*noexcept*函数)是为了保证与 std::thread 的析构函数的行为一致。

线程完成，或者分离它；进行赋值时也需要满足这些条件(说明：不能通过赋一个新值给 std::thread 对象的方式来"丢弃"一个线程)。  

std::thread 支持移动，就意味着线程的所有权可以在==函数外==进行转移，例如以下程序：

```c++
std::thread f() {
    void some_function();
    return std::thread(some_function);   // 返回出一个线程
}
std::thread g(){
    void some_other_function(int);
    std::thread t(some_other_function, 42);
    return t;
}
```

当所有权可以在函数内部传递，就允许 std::thread 实例可作为参数进行传递，代码如下：

```c++
void f(std::thread t);
void g() {
    void some_function();
    f(std::thread(some_function));
    std::thread t(some_function);
    f(std::move(t));
}
```

std::thread 支持移动的好处是可以创建thread_guard类的实例，并且拥有其线程所有权。当thread_guard对象所持有的线程被引用时，移动操作就可以避免很多不必要 的麻烦；这意味着，当某个对象转移了线程的所有权后，它就不能对线程进行加入或分离。 

为了确保线程程序退出前完成，下面的代码里定义了scoped_thread类。现在，我们来看一下这段代码： 

```c++
class scoped_thread {
    std::thread t;
public:
    explicit scoped_thread( std::thread t_ ) : t( std::move( t_ ) ) {  // 1
        if ( !t.joinable( ) )	// 2
        {
            throw std::logic_error( "No threasd" );
        }
    }
    ~scoped_thread( ) {
        t.join( );		//3
    }
    scoped_thread( scoped_thread const& ) = delete;
    scoped_thread& operator = ( scoped_thread  const& ) = delete;
};

struct func;

void f( ) {
    int some_local_stdte;
    scoped_thread t( std::thread( func( some_local_stdte ) ) );		//4
    do_something_in_current_thread( );		//5
}
```

新线程直接传递到scoped_thread中④，而非创建一个独立变量。当主线程到达f()函数末尾时⑤，scoped_thread对象就会销毁，然后加入③到的构造函数①创建的线 程对象中去。在的thread_guard类，需要在析构中检查线程是否"可加入"。这里把检查放在了构造函数中②，并且当线程不可加入时，抛出异常。 

这里对C++17标准给出一个建议，就是添加一个 joining_thread 的类型，这个类型 与 std::thread 类似；不同是的添加了析构函数，就类似于 scoped_thread。委员会成员们对此并没有达成统一共识，所以这个类没有添加入C++17标准中(C++20仍旧对这种方式进行探讨，不过名称为 std::jthread )，不过这个类实现起来也不是很困难。下面就来对这个类进行实现： 

joining_thread 类的实现：

```c++
class joining_thread {
    std::thread t;
public:
    joining_thread( ) noexcept = default;
    template<typename Callable, typename ... Args>
    explicit joining_thread( Callable&& func, Args&& ... args ) :
        t( std::forward<Callable>( func ), std::forward<Args>( args )... ) {}

    explicit joining_thread( std::thread t_ ) noexcept :
        t( std::move( t_ ) ) {}

    joining_thread( joining_thread&& other ) noexcept :
        t( std::move( other.t ) ) {}

    joining_thread& operator =( joining_thread&& other )noexcept {
        if ( joinable( ) )
        {
            join( );
        }
        t = std::move( other.t );
        return *this;
    }
    joining_thread& operator=( std::thread other ) noexcept {
        if ( joinable( ) )
        {
            join( );
        }
        t = std::move( other );
        return *this;
    }
    ~joining_thread( ) noexcept {
        if ( joinable( ) )
        {
            join( );
        }
    }
    
    void swap( joining_thread& other ) noexcept {
        t.swap( other.t );
    }
    
    std::thread::id get_id( ) const noexcept {
        return t.get_id( );
    }
    
    bool joinable( ) const noexcept {
        return t.joinable( );
    }
    
    void join( ) {
        t.join( );
    }
    
    void detach( ) {
        t.detach( );
    }
    
    std::thread& as_thread( ) noexcept {
        return t;
    }
    
    const std::thread& as_thread( ) const noexcept {
        return t;
    }
};
```

std::thread 对象的容器，如果这个容器是移动敏感的（比如，标准中的 std::vector<>），那么移动操作同样适用于这些容器。

```c++
void func( ) {
    std::vector<std::thread> threads;
    for ( unsigned i = 0; i < 20; ++i )
    {
        //产生线程
        threads.push_back( std::thread( [ ] ( unsigned id ) { std::cout << id << ' '; }, i ) );     
    }
    // 对每个线程调用 join
    std::for_each( threads.begin( ), threads.end( ), std::mem_fn( &std::thread::join ) );
}
```

如果需要线程分割一个算法的工作总量，所以在算法结束的之前，所有的线程必须结束。当中线程所做的工作都是独立的，并且结果仅会受到共享数据的影响。如果f()有返 回值，这个返回值就依赖于线程得到的结果。在写入返回值之前，程序会检查使用共享数据 的线程是否终止。

将 std::thread 放入 std::vector 是向线程自动化管理迈出的第一步：并非为这些线程创建独立的变量，并且直接加入，而是把它们当做一个组。创建一组线程(数量在运行时确定)，可使得这一步迈的更大。

## 运行时决定线程数量

std::thread::hardware_concurrency() 在新版C++标准库中是一个很有用的函数。这个函数会返回能并发在一个程序中的线程数量。例如，多核系统中，返回值可以是CPU核芯的数量。返回值也仅仅是一个提示，当系统信息无法获取时，函数也会返回0。但是，这也无法掩盖这个函数对启动线程数量的帮助。

实现了一个并行版的 std::accumulate 。代码中将整体工作拆分成小任务交给每个线 程去做，其中设置最小任务数，是为了避免产生太多的线程。程序可能会在操作数量为0的时候抛出异常。比如， std::thread 构造函数无法启动一个执行线程，就会抛出一个异常。 

```c++
template <typename Iterator, typename T>
struct acumulate_block {
    void operator()( Iterator first, Iterator last, T& result ) {
        result = std::accumulate( first, last, result );
    }
};

template<typename Iterator, typename T>
T parallel_accmulate( Iterator first, Iterator last, T init ) {
    unsigned long const length = std::distance( first, last );

    if ( !length )  //1
    {
        return init;
    }

    unsigned long const min_per_thread = 25;
    unsigned long const max_threads =
        ( length + min_per_thread - 1 ) / min_per_thread;   //2

    unsigned long const hardware_threads =
        std::thread::hardware_concurrency( );

    unsigned long const num_threads =   //3
        std::min( hardware_threads != 0 ? hardware_threads : 2, max_threads );

    unsigned long const block_size = length / num_threads;  //4 

    std::vector<T> results( num_threads );
    std::vector<std::thread> threads( num_threads - 1 );    //5

    Iterator block_start = first;

    for ( unsigned long i = 0; i < ( num_threads - 1 ); ++i )
    {
        Iterator block_end = block_start;
        std::advance( block_end, block_size );  // 6
        threads [ i ] = std::thread(    // 7
            acumulate_block<Iterator, T>( ),
            block_start, block_end, std::ref( results [ i ] ) );
            block_start = block_end;    //8
    }
    acumulate_block<Iterator, T>( )(
        block_start, last, results [ num_threads - 1 ] );   // 9

    std::for_each( threads.begin( ), threads.end( ), std::mem_fn( &std::thread::join ) );   //10

    return std::accumulate( results.begin( ), results.end( ), init );

}
```

函数看起来很长，但不复杂。如果输入的范围为空①，就会得到init的值。反之，如果范围内多于一个元素时，都需要用范围内元素的总数量==除以==线程(块)中最小任务数，从而确定启动线程的最大数量②，这样能避免无谓的计算资源的浪费。比如，一台32芯的机器上，只有5个数需要计算，却启动了32个线程。

计算量的最大值和硬件支持线程数中，==较小的值==为启动线程的数量③。因为上下文频繁的切换会降低线程的性能，所以你肯定不想启动的线程数多于硬件支持的线程数量。

当 std::thread::hardware_concurrency() 返回0，你可以选择一个合适的数作为你的选择；在本例中，我选择了"2"。你也不想在一台单核机器上启动太多的线程，因为这样反而会降低性能，有可能最终让你放弃使用并发。

每个线程中处理的元素数量,是范围中元素的总量除以线程的个数得出的④。

现在，确定了线程个数，通过创建一个 std::vector<T> 容器存放中间结果，并未线程创建一个 std::vector<std::thread> 容器 #5。 这里需要注意的是，==启动==的线程数必须比 num_threadd 少一个，因为在启动之前已经有了一个线程（主线程）。

使用简单的循环来启动线程：block_end 迭代器指向当前快的末尾 ⑥，并启动一个新线程为当前快累加结果 ⑦。当迭代器指向当前快的末尾时，启动下一个快 ⑧ 。

当累加最终块的结果后，可以等待 std::for_each ⑩创建线程的完成(如同在清单2.8中做的那样)，之后使用 std::accumulate 将所有结果进行累加⑪。

结束这个例子之前，需要明确：T类型的加法运算不满足结合律(比如，对于float型或double型，在进行加法操作时，系统很可能会做==截断==操作)，因为对范围中元素的分组，会导致parallel_accumulate得到的结果可能与 std::accumulate 得到的结果不同。同样的，这里对迭代器的要求更加严格：必须都是==向前迭代器==，而 std::accumulate 可以在只传入迭代器的情况下工作。对于创建出results容器，需要保证T有默认构造函数。对于算法并行，通常都要这样的修改；不过，需要根据算法本身的特性，选择不同的并行方式。

需要注意的：因为不能直接从一个线程中返回一个值，所以需要传递results容器的引用到线程中去。另一个办法，通过地址来获取线程执行的结果；

当线程运行时，所有必要的信息都需要传入到线程中去，包括存储计算结果的位置。不过，并非总需如此：有时候这是识别线程的可行方案，可以传递一个标识数，例如示例中的 i。

不过，当需要标识的函数在调用栈的深层，同时其他线程也可调用该函数，那么标识数就会变的捉襟见肘。好消息是在设计C++的线程库时，就有预见了这种情况，在之后的实现中就给每个线程附加了唯一标识符。

## 标识线程

线程标识类型为 ==std::thread::id== ，并可以通过两种方式进行检索。第一种，可以通过调用 std::thread 对象的成员函数 get_id() 来直接获取。如果 std::thread 对象没有与任何执行线程相关联， get_id() 将返回 std::thread::type 默认构造值，这个值表示“无线程”。第二种，当前线程中调用 std::this_thread::get_id() (这个函数定义在 <thread> 头文件中)也可以获得线程标识。

std::thread::id 对象可以自由的==拷贝和对比==,因为标识符就可以复用。如果两个对象的 std::thread::id 相等，那它们就是同一个线程，或者都“无线程”。如果不等，那么就代表了两个不同线程，或者一个有线程，另一没有线程。

C++线程库不会限制你去检查线程标识是否一样， std::thread::id 类型对象提供相当丰富的对比操作；比如，提供为不同的值进行排序。这意味着允许程序员将其当做为容器的键值，做排序，或做其他方式的比较。按默认顺序比较不同值的 std::thread::id ，所以这个行为可预见的：当 a<b ， b<c 时，得 a<c ，等等。标准库也提供 std::hash<std::thread::id> 容器，所以 std::thread::id 也可以作为无序容器的键值。

std::thread::id 实例常用作检测线程是否需要进行一些操作，比如：当用线程来分割一项工作，主线程可能要做一些与其他线程不同的工作。这种情况下，启动其他线程前，它可以将自己的线程ID通过 std::this_thread::get_id() 得到，并进行存储。就是算法核心部分(所有线程都一样的)，每个线程都要检查一下，其拥有的线程ID是否与初始线程的ID相同。

```c++
std::thread::id master_thread;
void some_core_part_of_algorithm( ) {
    if ( std::this_thread::get_id( ) == master_thread )  // 获取线程 id
    {
        // 其他操作
    }
    // 其他操作
}
```

另外，当前线程的 std::thread::id 将存储到一个数据结构中。之后在这个结构体中==对当前线程==的ID与存储的线程ID做对比，来决定操作是被“允许”，还是“需要”(permitted/required)。

同样，作为线程和本地存储不适配的替代方案，线程ID在容器中可作为键值。例如，容器可以存储其掌控下每个线程的信息，或在多个线程中互传信息。

 std::thread::id 可以作为一个线程的==通用标识符==，当标识符只与语义相关(比如，数组的索引)时，就需要这个方案了。也可以使用输出流( std::cout )来记录一个 std::thread::id 对象的值。

```c++
std::cout << std::this_thread::get_id();
```

具体的输出结果是严格依赖于具体实现的， c++ 标准的唯一要求就是要保证 id 比较结果相等的线程，必须有相同的输出。

## 共享线程数据带来的问题

涉及到共享数据时，问题就可能是因为共享数据修改所导致。如果共享数据是==只读==的，那么操作不会影响到数据，更不会涉及对数据的修改，所以所有线程都会获得同样的数据。但是，==当一个或多个线程要修改共享数据时==，就会产生很多麻烦。这种情况下，就必须小心谨慎，才能确保所有线程都工作正常。

不变量(invariants)的概念对开发者们编写的程序会有一定的帮助——对于特殊结构体的描述；比如，“变量包含列表中的项数”。不变量通常会在一次更新中被破坏，特别是比较复杂的数据结构，或者一次更新就要改动很大的数据结构。

双链表中每个节点都有一个指针指向列表中下一个节点，还有一个指针指向前一个节点。其中不变量就是节点A中指向“下一个”节点B的指针，还有前向指针。为了从列表中删除一个节点，其两边节点的指针都需要更新。当其中一边更新完成时，不变量就被破坏了，直到另一边也完成更新；在两边都完成更新后，不变量就又稳定了。

步骤：

1. 找到要删除的节点 N。
2. 更新前一个节点指向 N 的指针，在这个指针指向 N 的下一个节点。
3. 更新后一个节点指向 N 的指针，让这个指针指向 N 的前一个节点。
4. 删除节点 N。

![image-20230512104801500](C:\Users\Value.DESKTOP-F8NSHR6\AppData\Roaming\Typora\typora-user-images\image-20230512104801500.png)

图中b和c在相同的方向上指向和原来已经不一致了，这就破坏了不变量。

线程间的问题在于==修改共享数据==，致使不变量遭到破坏。当在删除过程中不确定是否有其他线程能够进行访问的话，可能就有线程访问到刚刚删除一边的节点；这样的话，==线程就读取到要删除节点的数据==(因为只有一边的连接被修改，如图3.1(b))，这样不变量就被破坏了。破坏不变量的后果是不确定的，当其他线程按从左往右的顺序来访问列表时，它将跳过被删除的节点。在一方面，如有第二个线程尝试删除图中右边的节点，那么可能会让数据结构产生永久性的损坏，使程序崩溃。无论结果如何，这都是并行中常见错误：==条件竞争(racecondition)==。

## c++ 中使用互斥量

c++中通过实例化 std::mutex 创建互斥量的实例，通过成员函数 lock() 对互斥量上锁，unlock() 进行解锁。不过，实践中不推荐直接调用成员函数，调用成员函数意就意味着，必须在每个函数出口都要去调用 unlock()，也包括异常的情况。c++ 标准库为互斥量提供了一个 RAII 语法的模板类 std::lock_guard，在构造时就能提供已锁的互斥量，并在析构的时候进行解锁，从而保证了一个互斥量就能被正确解锁。

以下的程序示例，展示了如何在多线程程序中，使用 std::mutex 构造的 std::lock_guard 实例，对一个列表进行访问保护。std::mutex 和 std::lock_guard 都在 <mutex> 头文件中声明。

```c++
#include<list>
#include<mutex>
#include<algorithm>

std::list<int> some_list;   //1
std::mutex some_mutex;  //2

void add_to_list( int new_value ) {
    std::lock_guard<std::mutex> guard( some_mutex );    //3 各自列表 创建互斥量
    some_list.push_back( new_value );
}

bool list_contains( int value_to_find ) {
    std::lock_guard<std::mutex> guard( some_mutex );    //4 各自列表
    return
        std::find( some_list.begin( ), some_list.end( ), value_to_find ) !=
        some_list.end( );
}
```

全局变量①，这个全局变量被一个全局的互斥量保护②。add_to_list()③和list_contains()④函数中使用 ==std::lock_guard<std::mutex>== ，使得这两个函数中对数据的访问是互斥的：list_contains()不可能看到正在被add_to_list()修改的列表。

C++17中添加了一个新特性，称为模板类参数推导，这样类似 std::locak_guard 这样简单的模板类型的模板参数列表可以省略。③和④的代码可以简化成：

```c++
std::lock_guard guard(some_mutex);
// 或者
std::scoped_lock guard(some_mutex);
```

某些情况下使用全局变量没问题，但在大多数情况下，==互斥量通常会与需要保护的数据放在同一类中==，而不是定义成全局量。这是面向对象设计的准则：将其放在一个类中，就可让他们联系在一起，也可对类的功能进行封装，并进行数据保护。这种情况下，函数==add_to_list和list_contains==可以作为这个类的成员函数。==互斥量和需要保护的数据，在类中都定义为private成员==，这会让访问数据的代码更清晰，并且容易看出在什么时候对互斥量上锁。当所有成员函数都会在调用时对数据上锁，结束时对数据解锁，这就保证了访问时数据不变量不被破坏。

当然，事情也不是总是那么理想，聪明的你一定注意到了：==当其中一个成员函数返回的是保护数据的指针或引用时，会破坏数据==。具有访问能力的指针或引用可以访问(并可能修改)被保护的数据，而不会被互斥锁限制。这就需要对接口有相当谨慎的设计，要确保互斥量能锁住数据的访问，并且不留后门。

### 用代码来保护共享数据

使用互斥量来保护数据，并不是仅仅在每一个成员函数中都加入一个 std::lock_guard 对象那么简单；一个指针或引用，也会让这种保护形同虚设。不过，检查指针或引用很容易，只要没有成员函数通过返回值或者输出参数的形式，向其调用者返回指向受保护数据的指针或引用，数据就是安全的。

如果你还想深究，就没这么简单了。确保成员函数不会传出指针或引用的同时，检查成员函数是否通过指针或引用的方式来调用也是很重要的(尤其是这个操作不在你的控制下时)。函数可能没在互斥量保护的区域内，存储着指针或者引用，这样就很危险。更危险的是：==将保护数据作为一个运行时参数，如同下面清单中所示那样==。

```c++
class some_data {
    int a;
    std::string b;
public:
    void do_something( );
};

class data_wrapper {
private:
    some_data data;
    std::mutex m;
public:
    template<typename Function>
    void process_data( Function func ) {
        std::lock_guard<std::mutex>l( m ); // 创建互斥量
        func( data );   // 1 传递“保护”函数给用户函数
    }
};

some_data* unprotected;
void malicious_function( some_data& protected_data ) {
    unprotected = &protected_data;
}

data_wrapper x;
void foo( ) {
    x.process_data( malicious_function );   //2 传递一个恶意函数
    unprotected->do_something( );   // 3 在无保护的情况下访问保护数据
}
```

例子中process_data看起来没有任何问题， std::lock_guard 对数据做了很好的保护，但==调用用户提供的函数func①，就意味着foo能够绕过==保护机制将函数 malicious_function 传递进去②，在没有锁定互斥量的情况下调用 do_something() 。

这段代码的问题在于根本没有保护，只是将所有可访问的数据结构代码标==记为互斥==。函数 foo() 中调用 unprotected->do_something() 的代码==未能被标记为互斥==。这种情况下，C++线程库无法提供任何帮助，只能由开发者使用正确的互斥锁来保护数据。从乐观的角度上看，还是有方法可循的：切勿将受保护数据的指针或引用传递到互斥锁作用域之外，无论是函数返回值，还是存储在外部可见内存，亦或是以参数的形式传递到用户提供的函数中去。

### 定位接口间的条件竞争

因为使用了==互斥量==或其他机制保护了共享数据，就不必再为条件竞争所担忧吗？并不是，你依旧需要确定数据是否受到了保护。回想之前双链表的例子，为了能让线程安全地删除一个节点，需要确保防止对这三个节点(待删除的节点及其前后相邻的节点)的==并发访问==。

如果只对指向每个节点的指针进行访问保护，那就和没有使用互斥量一样，条件竞争仍会发生——除了指针，整个数据结构和整个删除操作需要保护。这种情况下最简单的解决方案就是使用互斥量来保护整个链表。

尽管链表的个别操作是安全的，但不意味着你就能走出困境；即使在一个很简单的接口中，依旧可能遇到条件竞争。例如，构建一个类似于 ==std::stack 结构的栈==，除了构造函数和swap()以外，需要对 std::stack 提供五个操作：==push()一个新元素进栈，pop()一个元素出栈，top()查看栈顶元素，empty()判断栈是否是空栈，size()了解栈中有多少个元素==。

即使修改了top()，使其返回一个拷贝而非引用，对内部数据使用一个互斥量进行保护，不过这个接口仍存在条件竞争。这个问题不仅存在于基于互斥量实现的接口中，在无锁实现的接口中，条件竞争依旧会产生。这是接口的问题，与其实现方式无关。

std::stack 容器的实现：

```c++
template<typename T, typename Container = std::deque<T>>
class stack {
public:
    explicit stack( const Container& );
    explicit stack( Container && = Container( ) );
    template <class Alloc> explicit stack( const Alloc& );
    template <class Alloc> stack( const Container&, const Alloc& );
    template <class Alloc> stack( Container&&, const Alloc& );
    template <class Alloc> stack( stack&&, const Alloc& );

    bool empty( ) const;    // 判断栈是否是空栈
    size_t size( ) const;   // 了解栈中有多少个元素
    T& top( );
    T const& top( ) const;  // 查看栈顶元素
    void push( T const& );      // 添加一个新元素近栈
    void pop( );    // 取出一个元素出栈
    void swap( stack&& );
    tempalte<class... Args> void emplace( Args&&... args ); // c++14 的新特性
};
```

虽然empty()和size()可能在返回时是正确的，但其的结果是==不可靠的==；当它们返回后，其他线程就可以自由地访问栈，并且可能push()多个新元素到栈中，也可能pop()一些已在栈中的元素。这样的话，之前从empty()和size()得到的结果就有问题了。

当栈实例是非共享的，如果栈非空，使用empty()检查再调用top()访问栈顶部的元素是安全的。如下代码所示：

```c++
stack<int> s;  // 创建一个栈
if ( !s.empty( ) )  // 1 判断是否为空栈
{
    int const value = s.top( ); // 2 查看栈顶元素
    s.pop( );  // 3 取出一个栈顶元素
    do_something( value );  // 输出
}
```

以上是单线程安全代码：对一个==空栈使用top()是未定义行为==。对于共享的栈对象，这样的调用顺序就不再安全了，因为在用empty()①和调用top()②之间，可能有来自另一个线程的pop()调用并==删除了最后一个元素==。这是一个经典的条件竞争，使用互斥量对栈内部数据进行保护，但依旧不能阻止条件竞争的发生，这就是接口固有的问题。

怎么解决呢？问题发生在接口设计上，所以解决的方法也就是改变接口设计。有人会问：怎么改？在这个简单的例子中，当调用top()时，发现栈已经是空的了，那么就抛出异常。虽然这能直接解决这个问题，但这是一个笨拙的解决方案，这样的话，即使empty()返回false的情况下，你也需要异常捕获机制。本质上，这样的改变会让empty()成为一个多余函数。

当仔细的观察过之前的代码段，就会发现另一个潜在的条件竞争在调用top()②和pop()③之间。假设两个线程运行着前面的代码，并且都引用同一个栈对象s。这并非罕见的情况，当为性能而使用线程时，多个线程在==不同的数据上执行相同的操作==是很平常的，并且共享同一个栈可以将工作分摊给它们。假设，一开始栈中只有两个元素，这时任一线程上的empty()和top()都存在竞争，只需要考虑可能的执行顺序即可。

当栈被一个内部互斥量所保护时，只有一个线程可以调用栈的成员函数，所以调用可以很好地交错，并且do_something()是可以并发运行的。

```c++
#include<exception>
#include<memory>    // For std::shared_ptr<>

struct empty_stack : std::exception {
    const char* what( ) const throw( );
};

template<typename T>
class threadsafe_stack {
public:
    thread_local( );
    thread_local( const thread_local& );
    thread_local& operator =( const thread_local& ) = delete;

    // 1 赋值操作被删除
    void push( T ne_value );
    std::shared_ptr<T> pop( );  // std::shared_ptr<> 对象
    void pop( T& value );
    bool empty( ) const;
};
```

削减接口可以获得最大程度的安全,甚至限制对栈的一些操作。栈是不能直接赋值的，因为赋值操作已经删除了①，并且这里没有swap()函数。栈可以拷贝的，假设栈中的元素可以拷贝。==当栈为空时，pop()函数会抛出一个empty_stack异常==，所以在empty()函数被调用后，其他部件还能正常工作。如选项3描述的那样，使用 std::shared_ptr 可以避免内存分配管理的问题，并避免多次使用new和delete操作。堆栈中的五个操作，现在就剩下三个：push(), pop()和empty()(这里empty()都有些多余)。简化接口更有利于数据控制，可以保证互斥量将一个操作完全锁住。下面的代码将展示一个简单的实现——封装 std::stack<> 的线程安全堆栈。

扩充（线程安全）堆栈

```c++
#include<exception>
#include<memory>
#include<mutex>
#include<stack>

struct empty_stack : std::exception {
    const char* what( ) const throw( ) {
        return "empty stack!";
    };
};

template<typename T>
class threadsafe_stack {
private:
    std::stack<T> data;
    mutable std::mutex m;
public:
    threadsafe_stack( ) : data( std::stack<T>( ) ) {}

    threadsafe_stack( const threadsafe_stack& other ) {
        std::lock_guard<std::mutex> lock( other.m );
        data = other.data;  // 1 在构造函数体中的执行拷贝
    }
    threadsafe_stack& operator=( const threadsafe_stack& ) = delete;
    void push( T new_valeu ) {
        std:::lock_guard<std::mutex> lock( m );
        data.push( new_valeu );
    }
    std::shared_ptr<T> pop( ) {
        std::lock_guard<std::mutex> lock( m );
        if ( data.empty( ) )
        {
            throw empty_stack( );   //在调用 pop 前，检查栈是否为空
        }
        // 在修改堆栈前，分配出返回值
        std::shared_ptr<T> const res( std::make_shared<T>( data.top( ) ) );
        data.pop( );
        return res;
    }
    void pop( T& value ) {
        std::lock_guard<std::mutex> lock( m );
        if ( data.empty( ) )
        {
            throw empty_stack( );
        }
        value = data.top( );
        data.pop( );
    }
    bool empty( ) const {
        std::lock_guard<std::mutex> lock( m );
        return data.empty( );
    }
};
```

==堆栈可以拷贝——拷贝构造函数对互斥量上锁，再拷贝堆栈==。构造函数体中①的拷贝使用==互斥量==来确保复制结果的正确性，这样的方式比成员初始化列表好。

之前对top()和pop()函数的讨论中，恶性条件竞争已经出现，因为锁的粒度太小，需要保护的操作并未全覆盖到。不过，锁住的颗粒过大同样会有问题。还有一个问题，一个==全局互斥量要去保护全部共享数据==，在一个系统中存在有大量的共享数据时，因为线程可以强制运行，甚至可以访问不同位置的数据，==抵消了并发带来的性能提升==。

第一版为多处理器系统设计Linux内核中，就使用了一个全局内核锁。虽然这个锁能正常工作，但在双核处理系统的上的
性能要比两个单核系统的性能差很多，四核系统就更不能提了。太多请求去竞争占用内核，使得依赖于处理器运行的线程没有办法很好的工作。随后修正的Linux内核加入了一个==细粒度锁方案==，因为少了很多内核竞争，这时四核处理系统的性能就和单核处理的四倍差不多了。

使用多个互斥量保护所有的数据，细粒度锁也有问题。如前所述，当增大互斥量覆盖数据的粒度时，==只需要锁住一个互斥量==。但是，这种方案并非放之四海皆准，比如：互斥量正在保护一个独立类的实例；这种情况下，锁的状态的下一个阶段，不是离开锁定区域将锁定区域还给用户，就是有独立的互斥量去保护这个类的全部实例。

当然，这两种方式都不理想。一个给定操作需要两个或两个以上的互斥量时，另一个潜在的问题将出现：==死锁==。与条件竞争完全相反——不同的两个线程会互相等待，从而什么都没做。

### 死锁：问题描述及解决方案

线程有对锁的竞争：一对线程需要对他们所有的==互斥量==做一些操作，其中每个线程都有一个互斥量，且等待另一个==解锁==。这样没有线程能工作，因为他们都在等待对方释放互斥量。这种情况就是==死锁==，它的最大问题就是由==两个或两个以上的互斥量来锁定一个操作==。

避免死锁的一般建议，就是让两个互斥量总以相同的顺序上锁：总在互斥量B之前锁住互斥量A，就永远不会死锁。某些情况下是可以这样用，因为不同的互斥量用于不同的地方。

不过，事情没那么简单，比如：当有多个互斥量保护同一个类的独立实例时，一个操作对同一个类的两个不同实例进行数据的交换操作，为了保证数据交换操作的正确性，就要避免数据被并发修改，并==确保每个实例上的互斥量都能锁住自己要保护的区域==。不过，选择一个固定的顺序(例如，实例提供的第一互斥量作为第一个参数，提供的第二个互斥量为第二个参数)，可能会适得其反：在参数交换了之后，两个线程试图在相同的两个实例间进行数据交换时，程序又==死锁==了！

很幸运，C++标准库有办法解决这个问题， ==std::lock== ——可以==一次性锁住多个==(两个以上)的互斥量，并且没有副作用(死锁风险)。下面的程序清单中，就来看一下怎么在一个简单的交换操作中使用 std::lock 。

交换操作中使用 std::lock() 和 std:::lock_guard

```c++
// 这里的 std::lock() 需要包含 <mutex> 头文件
class some_big_object;
void swap( some_big_object& lhs, some_big_object& rhs );
class X {
private:
    some_big_object some_detail;
    std::mutex m;
public:
    X( some_big_object const& sd ) : some_detail( sd ) {}
    friend void swap( X& lhs, X& rhs ) {
        if ( &lhs == &rhs )
        {
            return;
        }
        std::lock( lhs.m, rhs.m );  // 1  锁住两个互斥量
        std::lock_guard<std::mutex> lock_a( lhs.m, std::adopt_lock );   // 2
        std::lock_guard<std::mutex> lock_b( rhs.m, std::adopt_lock );   // 3
        swap( lhs.some_detail, rhs.some_detail );
    }
};
```

首先，==检查参数是否是不同的实例==，因为操作试图获取 std::mutex 对象上的锁，所以当其被获取时，结果很难预料。(一个互斥量可以在同一线程上==多次上锁==，标准库中 ==std::recursive_mutex 提供这样的功能==。)。然后，调用 ==std::lock() ①锁住两个互斥量==，并且两个 std:lock_guard 实例已经创建好②③。提供 std::adopt_lock 参数除了表示 std::lock_guard 对象可获取锁之外，还将锁交由 std::lock_guard 对象管理，而不需要 std::lock_guard 对象再去构建新的锁。

这样，就能保证在大多数情况下，函数退出时互斥量能被正确的解锁(保护操作可能会抛出一个异常)，也允许使用一个简单的“return”作为返回。还有，当使用 std::lock 去锁lhs.m或rhs.m时，可能会抛出异常；这种情况下，异常会传播到 std::lock 之外。当 std::lock 成功的获取一个互斥量上的锁，并且当其尝试从另一个互斥量上再获取锁时，就会有异常抛出，第一个锁也会随着异常的产生而自动释放，所以 std::lock 要么将两个锁都锁住，要不一个都不锁。

C++17对这种情况提供了支持， ==std::scoped_lock<> 一种新的RAII类型模板类型，与 std::lock_guard<> 的功能等价==，这个新类型能接受不定数量的互斥量类型作为模板参数，以及相应的互斥量(数量和类型)作为构造参数。互斥量支持构造即上锁，与 std::lock 的用法相同，其解锁阶段是在析构中进行。

例如：swap() 操作可以重写如下：

```c++
void swap(X& lhs, X& rhs) {
    if(&lhs == &rhs) return;
    std::scoped_lock guard(lhs.m, rhs.m);	// 1
    swap(lhs.some_detail, rhs.some_detail);
}
```

这里使用了C++17的另一个特性：==自动推导模板参数==。如果你手头上有支持C++17的编译器(那你就能使用 std::scoped_lock 了，因为其是C++17标准库中的一个工具)，==C++17可以通过隐式参数模板类型推导机制==， 通过传递的对形象类型来构造实例①。

这行代码等价于下面参数全给的版本：

```c++
std::scoped_lock<std::mutex, std::mutex> guard(lhs.m, rhs.m);
```

std::scoped_lock 的好处在于，可以将所有 std::lock 替换掉，从而减少潜在错误的发生。虽然 std::lock (和 std::scoped_lock<> )可以在这情况下(获取两个以上的锁)避免死锁，但它没办法帮助你获取其中一个锁。这时，==依赖于开发者的纪律性(译者：也就是经验)，来确保你的程序不会死锁==。

这并不简单：死锁是多线程编程中一个令人相当头痛的问题，并且死锁经常是不可预见的，因为在大多数时间里，所有工作都能很好的完成。不过，一些相对简单的规则能帮助写出“无死锁”的代码。

使用锁得层次结构

虽然，定义锁得顺序是一种特殊情况，但锁的层次的意义在于提供对运行时约定是否被坚持的检查。这个建议需要对你的应用进行分层，并且识别在给定层上所有可上锁的互斥量。当代码试图对一个互斥量上锁，在该层锁已被低层持有时，上锁是不允许的。你可以在运行时对其进行检查，通过分配层数到每个互斥量上，以及记录被每个线程上锁的互斥量。下面的
代码列表中将展示两个线程如何使用分层互斥。

使用层次锁来避免死锁

```c++
// 伪代码
hierarchical_mutex high_level_mutex( 10000 );   //1
hierarchical_mutex low_level_mutex( 5000 );     //2
hierarchical_mutex other_mutex( 6000 );     //3

int do_low_level_stuff( );

int low_level_func( ) {
    std::lock_guard < hierarchical_mutex> lk( low_level_func );     //4
    return do_low_level_stuff( );
}

void high_level_stuff( int some_param );

void high_level_func( ) {
    std::lock_guard<high_level_mutex> lk( high_level_mutex );   //6
    high_level_stuff( low_level_func( ) );  //5
}

void thread_a( ) {     //7
    high_level_func( );
}

void other_stuff( ) {
    high_level_func( );     //10
    do_other_stuff( );
}

void thread_b( ) {      //8
    std::lock_guard<hierarchical_mutex> lk( other_mutex );  //9
    other_stuff( );
}
```

这段代码有三个hierarchical_mutex实例(①，②和③)，其==通过逐渐递减的层级数量进行构造==。根据已经定义好的机制，如你已将一个hierarchical_mutex实例进行上锁，那么你只能获取更低层级hierarchical_mutex实例上的锁，这就会对代码进行一些限制。

假设do_low_level_stuff不会对任何互斥量进行上锁，low_level_func为层级最低的函数，并且会对low_level_mutex④进行上锁。high_level_func调用low_level_func⑤的同时，也持有high_level_mutex⑥上的锁，这也没什么问题，因为==high_level_mutex(①：10000)要比low_level_mutex(②：5000)更高级==。

thread_a()⑦遵守规则，所以它运行的没问题。

另一方面，thread_b()⑧无视规则，因此在运行的时候肯定会失败。

首先，thread_b锁住了other_mutex⑨，这个互斥量的层级值只有6000③。这就意味着，==中层级的数据已被保护==。当other_stuff()调用high_level_func()⑧时，就违反了层级结构：high_level_func()试图获取high_level_mutex，这个互斥量的层级值是10000，要比当前层级值6000==大很多==。因此hierarchical_mutex将会产生一个==错误==，可能会是抛出一个异常，或直接终止程序。在层级互斥量上产生死锁，是不可能的，因为互斥量本身会严格遵循约定顺序，进行上锁。这也意味，当多个互斥量在是在同一级上时，不能同时持有多个锁，所以“手递手”锁的方案需要每个互斥量在一条链上，并且每个互斥量都比其前一个有更低的层级值，这在某些情况下无法实现。

例子也展示了另一点， ==std::lock_guard<> 模板与用户定义的互斥量类型一起使用==。虽然hierarchical_mutex不是C++标准的一部分，但是它写起来很容易；尽管它是一个用户定义类型，它可以用于 std::lock_guard<> 模板中，因为它的实现有三个成员函数为了满足互斥量操作：==lock(), unlock() 和 try_lock()==。虽然你还没见过try_lock()怎么使用，但是其使用起来很简单：当互斥量上的锁被一个线程持有，它将返回false，而==不是等待调用的线程，直到能够获取互斥量上的锁为止。在 std::lock() 的内部实现中，try_lock()会作为避免死锁算法的一部分==。

```c++

class hierarchical_mutex {
    std::mutex internal_mutex;

    unsigned long const hirerarchy_value;
    unsigned long previous_hierarchy_value;

    static thread_local unsigned long this_thread_hirearchy_value;  //1

    void check_for_hierarchy_violation( ) {
        if ( this_thread_hirearchy_value <= hirerarchy_value )      //2
        {
            throw std::logic_error( "mutex hierarchy violated" );
        }
    }
    void update_hierarchy_value( ) {
        previous_hierarchy_value = this_thread_hirearchy_value; //3
        this_thread_hirearchy_value = hirerarchy_value;
    }
public:
    explicit hierarchical_mutex( unsigned long value ) :
        hirerarchy_value( value ), previous_hierarchy_value( 0 ) {}

    void lock( ) {
        check_for_hierarchy_violation( );
        internal_mutex.lock( );     //4
        update_hierarchy_value( );      //5
    }
    void unlock( ) {
        if ( this_thread_hirearchy_value != hirerarchy_value )
        {
            throw std::logic_error( "mutex hierarchy violated" );   //9
        }
        this_thread_hirearchy_value = previous_hierarchy_value;
        internal_mutex.unlock( );
    }
    bool try_lock( ) {
        check_for_hierarchy_violation( );
        if ( !internal_mutex.try_lock( ) )  // 7
        {
            return false;
        }
        update_hierarchy_value( );
        return true;
    }
};

thread_local unsigned long hierarchical_mutex::this_thread_hirearchy_value( ULONG_MAX );


```

这里重点是使用了 thread_local 的值类代表当前线程的层级值：

this_thread_hierarchy_value①。==它被初始化为最大值⑧，所以最初所有线程都能被锁住==。因为其声明中有thread_local，所以每个线程都有其==拷贝副本==，这样线程中变量状态完全==独立==，当从另一个线程进行读取时，变量的状态也完全独立。

所以，第一次线程锁住一个hierarchical_mutex时，this_thread_hierarchy_value的值是 ULONG_MAX。由于其本身的性质，这个值会大于其他任何值，所以会通过check_for_hierarchy_vilation()② 的检查。在这种检查方式下，lock()代表内部互斥锁==已被锁住==④。一旦成功锁住，你可以更新层级值了⑤。

当你现在锁住另一个hierarchical_mutex（副本）时，还持有第一个锁，this_thread_hierarchy_value的值将会==显示第一个互斥量的层级值==。第二个互斥量的层级值必须==小于已经持有互斥量检查函数②才能通过==。

现在，最重要的是为当前线程存储之前的层级值，所以你可以调用 unlock()⑥对==层级值进行保存==；否则，就锁不住任何互斥量(第二个互斥量的层级数高于第一个互斥量)，即使线程没有持有任何锁。因为保存了之前的层级值，只有当持有internal_mutex③，且在解锁内部互斥量⑥之前存储它的层级值，才能安全的将hierarchical_mutex自身进行存储。这是因为hierarchical_mutex被==内部互斥量的锁所保护着==。为了避免无序解锁造成层次结构混乱，==当解锁的互斥量不是最近上锁的那个互斥量==，就需要抛出异常⑨。其他机制也能做到这点，但目前这个是最简单的。

try_lock()与lock()的功能相似，除了在调用internal_mutex的try_lock()⑦失败时，==不能持有对应锁，所以不必更新层级值，并直接返回false==。虽然是运行时检测，但是它没有时间依赖性——不必去等待导致死锁出现的罕见条件。同时，设计过程需要去拆分应用，互斥量在这种情况下可以消除导致死锁的可能性。这样的练习很有必要去做一下，即使你之后没有去做，代码也会在运行时进行检查。

代码已能规避死锁， std::lock() 和 std::lock_guard 可==组成简单的锁==，并覆盖大多数情况，但是有时需要更多的灵活性。在这种情况下，可以使用标准库提供的 ==std::unique_lock 模板==。如 std::lock_guard ，这是一个==参数化的互斥量模板类==，并且它提供很多 RAII 类型锁用来管理 std::lock_guard 类型，可以让代码更加灵活。

